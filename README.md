### multimodal_style_transfer
You may download our trained style transfer model and our trained segmetation model [here](https://drive.google.com/drive/folders/1f_is4RvnXGHroIAij4kiW-eAj-jU-Ts9?usp=sharing), which is based on the approach developed by the Inom Miraev team with style transfer as augmentation.

### References
[1] Implementation https://github.com/HsinYingLee/MDMM and paper https://arxiv.org/abs/1905.01270. Lee, H.Y., Tseng, H.Y., Mao, Q., Huang, J.B., Lu, Y.D., Singh, M., Yang, M.H.: DRIT : Diverse Image-to-Image translation via disentangled representations (2020)
